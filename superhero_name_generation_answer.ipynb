{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> #Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dc = 'dc-wikia-data.csv'\n",
    "path_marvel = 'marvel-wikia-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "    def __init__(self, all_names, pad_idx=0, sos_idx=1, eos_idx=2, unk_idx=3, min_freq=50):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.unk_idx = unk_idx\n",
    "        self.min_freq = min_freq\n",
    "        #count frequency of chars\n",
    "        self.vocab = Counter(list(chain(*all_names)))\n",
    "        #create char to index dictionaries\n",
    "        self.char2idx = {'<pad>': self.pad_idx,\n",
    "                         '<sos>': self.sos_idx, \n",
    "                         '<eos>': self.eos_idx,\n",
    "                         '<unk>': self.unk_idx}\n",
    "        index = 3\n",
    "        for char, freq in self.vocab.items():\n",
    "            if freq > self.min_freq:\n",
    "                index += 1\n",
    "                self.char2idx[char] = index\n",
    "            else:\n",
    "                self.char2idx[char] = self.unk_idx\n",
    "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
    "        self.idx2char[self.unk_idx] = '<unk>'\n",
    "        self.vocab_size = len(set(self.char2idx.values()))\n",
    "        \n",
    "    def encode_string(self, string):\n",
    "        return [self.char2idx[char] for char in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padding():\n",
    "    def padding(self, batch_string, pad_idx):\n",
    "        '''adds regular padding to string'''\n",
    "        max_len = max(map(len, batch_string))\n",
    "        padded_batch = []\n",
    "        for string in batch_string:\n",
    "            number_padding = max_len - len(string)\n",
    "            padded_string = string + [pad_idx] * number_padding\n",
    "            padded_batch.append(padded_string)\n",
    "        return padded_batch\n",
    "    \n",
    "    def add_eos_sos(self, batch_string, sos_idx, eos_idx):\n",
    "        '''adds end of string and start of string padding'''\n",
    "        sos_batch = []\n",
    "        eos_batch = []\n",
    "        for string in batch_string:\n",
    "            sos_string = [sos_idx] + string\n",
    "            eos_string = string + [eos_idx]\n",
    "            sos_batch.append(sos_string)\n",
    "            eos_batch.append(eos_string)\n",
    "        return sos_batch, eos_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Vocabulary):\n",
    "    def __init__(self, path_dc, path_marvel):\n",
    "        self.all_names = self.load_dataset(path_dc, path_marvel)\n",
    "        #to char represantation of name\n",
    "        self.all_names = list(map(list, self.all_names))\n",
    "        self.vocab = Vocabulary(self.all_names)\n",
    "        self.padding = Padding()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_names)\n",
    "    \n",
    "    def load_dataset(self, path_dc, path_marvel):\n",
    "        dc_df = pd.read_csv(path_dc)\n",
    "        marvel_df = pd.read_csv(path_marvel)\n",
    "        df = dc_df.append(marvel_df, sort=False)\n",
    "        all_names = (df.name.str.replace('\\((.*?)\\)', '')\n",
    "                     .str.strip()\n",
    "                     .str.lower()\n",
    "                     .unique())\n",
    "        return all_names\n",
    "    \n",
    "    def get_batch(self, batch_size):\n",
    "        batch_chars = [self.all_names[np.random.randint(len(self.all_names))] \n",
    "                       for _ in range(batch_size)]\n",
    "        #to index\n",
    "        batch_numbers = [self.vocab.encode_string(string) for string in batch_chars]\n",
    "        #add padding\n",
    "        batch_numbers = self.padding.padding(batch_numbers, pad_idx=self.vocab.pad_idx)\n",
    "        batch_in, batch_out = self.padding.add_eos_sos(batch_numbers, \n",
    "                                               sos_idx=self.vocab.sos_idx, \n",
    "                                               eos_idx=self.vocab.eos_idx)\n",
    "        batch_in = torch.LongTensor(batch_in)\n",
    "        batch_out = torch.LongTensor(batch_out)\n",
    "        return batch_in, batch_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, pad_idx):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        #making layers\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=pad_idx)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, batch_in, hidden=None):\n",
    "        embedded_chars = self.embedding(batch_in)\n",
    "        if hidden is not None:\n",
    "            outputs, hidden = self.gru(embedded_chars, hidden)\n",
    "        else:\n",
    "            outputs, hidden = self.gru(embedded_chars)\n",
    "        logits = self.linear(outputs)\n",
    "        logits = logits.view(-1, self.vocab_size)\n",
    "        return logits, hidden\n",
    "    \n",
    "    def generate(self, determined, vocab):\n",
    "        start_char = torch.LongTensor([[vocab.sos_idx]]).to(device)\n",
    "        generated_name = [start_char]\n",
    "        hidden = torch.zeros(1, 1, self.hidden_size).to(device)\n",
    "        for _ in range(15):\n",
    "            logit, hidden = self.forward(generated_name[-1], hidden)\n",
    "            if determined:\n",
    "                char = logit.topk(1)[1]\n",
    "            else:\n",
    "                char = F.softmax(logit, dim=1).multinomial(1)\n",
    "            generated_name.append(char)\n",
    "            if char.item() == vocab.eos_idx:\n",
    "                break\n",
    "        generated_name = [vocab.idx2char[char.item()] for char in generated_name \n",
    "                          if char not in  [vocab.pad_idx, \n",
    "                                           vocab.eos_idx, \n",
    "                                           vocab.sos_idx]]\n",
    "        generated_name = ''.join(generated_name[1:])\n",
    "        return generated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(epoch, loss):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(losses)\n",
    "    plt.title(f'Epoch:{epoch}|Loss:{np.mean(losses[-100:]):.4f}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_name(epoch, logits, batch_out, vocab):\n",
    "    logit = logits.view(batch_size, -1, vocab.vocab_size)[0]\n",
    "    truth_name = batch_out[0]\n",
    "    generated_name = logit.topk(1)[1]\n",
    "    generated_name = [vocab.idx2char[char.item()] for char in generated_name \n",
    "                      if char not in [vocab.pad_idx, vocab.eos_idx]]\n",
    "    generated_name = ''.join(generated_name)\n",
    "    truth_name = [vocab.idx2char[char.item()] for char in truth_name \n",
    "                  if char not in [vocab.pad_idx, vocab.eos_idx]]\n",
    "    truth_name = ''.join(truth_name)\n",
    "    print('--------')\n",
    "    print(f'Epoch:{epoch}\\n Predicted: {generated_name}\\n Truth: {truth_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(path_dc, path_marvel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dataset.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "emb_size = 64\n",
    "hidden_size = 256\n",
    "vocab_size = vocab.vocab_size\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(vocab_size, emb_size, hidden_size, vocab.pad_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "to_print_loss = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Epoch:0\n",
      " Predicted: mrrerbh moaloerdarr\n",
      " Truth: bobo t. chimpanzee\n",
      "Loss:2.1740\n",
      "--------\n",
      "Epoch:1\n",
      " Predicted: saramhemgers\n",
      " Truth: mad thinker\n",
      "Loss:2.0320\n",
      "--------\n",
      "Epoch:2\n",
      " Predicted: meon mtarfeerd \n",
      " Truth: leah sheffield\n",
      "Loss:1.9179\n",
      "--------\n",
      "Epoch:3\n",
      " Predicted: maar e cilneoighte\n",
      " Truth: dwayne wainwright\n",
      "Loss:1.8450\n",
      "--------\n",
      "Epoch:4\n",
      " Predicted: mecd tibbeeng\n",
      " Truth: luna nurblin\n",
      "Loss:1.7941\n",
      "--------\n",
      "Epoch:5\n",
      " Predicted: snoin haresta\n",
      " Truth: irwin hayes\n",
      "Loss:1.7492\n",
      "--------\n",
      "Epoch:6\n",
      " Predicted: son liah srnhries\n",
      " Truth: jebediah guthrie\n",
      "Loss:1.7037\n",
      "--------\n",
      "Epoch:7\n",
      " Predicted: saalerra \n",
      " Truth: stygorr\n",
      "Loss:1.6744\n",
      "--------\n",
      "Epoch:8\n",
      " Predicted: maroer o  \n",
      " Truth: barker\n",
      "Loss:1.6491\n",
      "--------\n",
      "Epoch:9\n",
      " Predicted: maeve  carkioneer\n",
      " Truth: steven partridge\n",
      "Loss:1.6095\n",
      "--------\n",
      "Epoch:10\n",
      " Predicted: marvisua   \n",
      " Truth: calculha\n",
      "Loss:1.5918\n",
      "--------\n",
      "Epoch:11\n",
      " Predicted: sntreu00e<unk>  \n",
      " Truth: andr\\u00e<unk>\n",
      "Loss:1.5817\n",
      "--------\n",
      "Epoch:12\n",
      " Predicted: milliam kacterso\n",
      " Truth: william vickers\n",
      "Loss:1.5392\n",
      "--------\n",
      "Epoch:13\n",
      " Predicted: alzeathoaa\n",
      " Truth: azimuth\n",
      "Loss:1.5199\n",
      "--------\n",
      "Epoch:14\n",
      " Predicted: sacon braneo\n",
      " Truth: jason dean\n",
      "Loss:1.5080\n",
      "--------\n",
      "Epoch:15\n",
      " Predicted: mriver ooaod-anmto\n",
      " Truth: oliver broadhurst\n",
      "Loss:1.4938\n",
      "--------\n",
      "Epoch:16\n",
      " Predicted: mavtnaa o \n",
      " Truth: decay\n",
      "Loss:1.4637\n",
      "--------\n",
      "Epoch:17\n",
      " Predicted: sanie d   \n",
      " Truth: dangor\n",
      "Loss:1.4546\n",
      "--------\n",
      "Epoch:18\n",
      " Predicted: mlward wanensere\n",
      " Truth: edward lavender\n",
      "Loss:1.4480\n",
      "--------\n",
      "Epoch:19\n",
      " Predicted: saarinen    \n",
      " Truth: shuriken\n",
      "Loss:1.4281\n",
      "--------\n",
      "Epoch:20\n",
      " Predicted: sartain s'tkass\n",
      " Truth: captain osaki\n",
      "Loss:1.4227\n",
      "--------\n",
      "Epoch:21\n",
      " Predicted: malra ii \n",
      " Truth: xiong\n",
      "Loss:1.3917\n",
      "--------\n",
      "Epoch:22\n",
      " Predicted: sarler sacholse\n",
      " Truth: carter nichols\n",
      "Loss:1.4006\n",
      "--------\n",
      "Epoch:23\n",
      " Predicted: merikit  \n",
      " Truth: havok\n",
      "Loss:1.3834\n",
      "--------\n",
      "Epoch:24\n",
      " Predicted: sarltaker o\n",
      " Truth: caretaker\n",
      "Loss:1.3635\n",
      "--------\n",
      "Epoch:25\n",
      " Predicted: mhblopseuo \n",
      " Truth: cyclops\n",
      "Loss:1.3457\n",
      "--------\n",
      "Epoch:26\n",
      " Predicted: mavk usumia\n",
      " Truth: daramulum\n",
      "Loss:1.3508\n",
      "--------\n",
      "Epoch:27\n",
      " Predicted: mnesea sasterso\n",
      " Truth: alicia masters\n",
      "Loss:1.3375\n",
      "--------\n",
      "Epoch:28\n",
      " Predicted: srtzkashu\n",
      " Truth: fazekas\n",
      "Loss:1.3234\n",
      "--------\n",
      "Epoch:29\n",
      " Predicted: malnis rlazrer\n",
      " Truth: corvus glaive\n",
      "Loss:1.3287\n",
      "--------\n",
      "Epoch:30\n",
      " Predicted: srdo-te te\n",
      " Truth: antiope\n",
      "Loss:1.3242\n",
      "--------\n",
      "Epoch:31\n",
      " Predicted: mary aolykr\n",
      " Truth: gary cody\n",
      "Loss:1.2886\n",
      "--------\n",
      "Epoch:32\n",
      " Predicted: sarra geanden \n",
      " Truth: moira brandon\n",
      "Loss:1.2940\n",
      "--------\n",
      "Epoch:33\n",
      " Predicted: saishersk\n",
      " Truth: smathers\n",
      "Loss:1.2838\n",
      "--------\n",
      "Epoch:34\n",
      " Predicted: mhave kosldsti\n",
      " Truth: traci fields\n",
      "Loss:1.2898\n",
      "--------\n",
      "Epoch:35\n",
      " Predicted: mochard mleg, jr.\n",
      " Truth: richard flag, jr.\n",
      "Loss:1.2781\n",
      "--------\n",
      "Epoch:36\n",
      " Predicted: mar me mirsons\n",
      " Truth: maxine gibson\n",
      "Loss:1.2696\n",
      "--------\n",
      "Epoch:37\n",
      " Predicted: mamk oallsnct\n",
      " Truth: jack holyoak\n",
      "Loss:1.2656\n",
      "--------\n",
      "Epoch:38\n",
      " Predicted: sananda frindersoe\n",
      " Truth: selinda flinders\n",
      "Loss:1.2667\n",
      "--------\n",
      "Epoch:39\n",
      " Predicted: shevlecerpente\n",
      " Truth: steel serpent\n",
      "Loss:1.2508\n",
      "--------\n",
      "Epoch:40\n",
      " Predicted: marcscieer \n",
      " Truth: landslide\n",
      "Loss:1.2509\n",
      "--------\n",
      "Epoch:41\n",
      " Predicted: mltsses lloodstone\n",
      " Truth: ulysses bloodstone\n",
      "Loss:1.2549\n",
      "--------\n",
      "Epoch:42\n",
      " Predicted: man y sohnson \n",
      " Truth: daisy johnson\n",
      "Loss:1.2446\n",
      "--------\n",
      "Epoch:43\n",
      " Predicted: shmy devai\n",
      " Truth: tone-def\n",
      "Loss:1.2343\n",
      "--------\n",
      "Epoch:44\n",
      " Predicted: sanm  de toa\n",
      " Truth: duela dent\n",
      "Loss:1.2259\n",
      "--------\n",
      "Epoch:45\n",
      " Predicted: manda wtrausse\n",
      " Truth: linda strauss\n",
      "Loss:1.2305\n",
      "--------\n",
      "Epoch:46\n",
      " Predicted: mellyguvis \n",
      " Truth: bill davis\n",
      "Loss:1.2291\n",
      "--------\n",
      "Epoch:47\n",
      " Predicted: soromy walson \n",
      " Truth: jeremy wilson\n",
      "Loss:1.2255\n",
      "--------\n",
      "Epoch:48\n",
      " Predicted: mann  darsero\n",
      " Truth: liana feeser\n",
      "Loss:1.2149\n",
      "--------\n",
      "Epoch:49\n",
      " Predicted: shrult beiesaiai\n",
      " Truth: tybalt bak'sar\n",
      "Loss:1.2200\n",
      "--------\n",
      "Epoch:50\n",
      " Predicted: srt. chaser \n",
      " Truth: o.z. chase\n",
      "Loss:1.2041\n",
      "--------\n",
      "Epoch:51\n",
      " Predicted: melen claisaanov\n",
      " Truth: helen feliciano\n",
      "Loss:1.2097\n",
      "--------\n",
      "Epoch:52\n",
      " Predicted: jrzarro fommy olsen \n",
      " Truth: bizarro jimmy olsen\n",
      "Loss:1.2005\n",
      "--------\n",
      "Epoch:53\n",
      " Predicted: manelle\n",
      " Truth: cybill\n",
      "Loss:1.2001\n",
      "--------\n",
      "Epoch:54\n",
      " Predicted: maaimick holaes\n",
      " Truth: sherlock holmes\n",
      "Loss:1.1963\n",
      "--------\n",
      "Epoch:55\n",
      " Predicted: manista t  \n",
      " Truth: sadista\n",
      "Loss:1.2026\n",
      "--------\n",
      "Epoch:56\n",
      " Predicted: maagonrn  \n",
      " Truth: dragorin\n",
      "Loss:1.2013\n",
      "--------\n",
      "Epoch:57\n",
      " Predicted: srnlwacer\n",
      " Truth: beefcake\n",
      "Loss:1.2283\n",
      "--------\n",
      "Epoch:58\n",
      " Predicted: marrh e u\n",
      " Truth: myrrt\n",
      "Loss:1.1905\n",
      "--------\n",
      "Epoch:59\n",
      " Predicted: ahr tavsoni\n",
      " Truth: tex dawson\n",
      "Loss:1.2038\n",
      "--------\n",
      "Epoch:60\n",
      " Predicted: aartua colpers\n",
      " Truth: marcie cooper\n",
      "Loss:1.1831\n",
      "--------\n",
      "Epoch:61\n",
      " Predicted: markise  \n",
      " Truth: machine\n",
      "Loss:1.1878\n",
      "--------\n",
      "Epoch:62\n",
      " Predicted: mlizabeth brnder\n",
      " Truth: elizabeth bondi\n",
      "Loss:1.1860\n",
      "--------\n",
      "Epoch:63\n",
      " Predicted: aaleter a\n",
      " Truth: ceyote\n",
      "Loss:1.1790\n",
      "--------\n",
      "Epoch:64\n",
      " Predicted: marlono,  \n",
      " Truth: karsano\n",
      "Loss:1.1940\n",
      "--------\n",
      "Epoch:65\n",
      " Predicted: mlhan saorma\n",
      " Truth: ethan thurm\n",
      "Loss:1.1965\n",
      "--------\n",
      "Epoch:66\n",
      " Predicted: mrrlln a    \n",
      " Truth: fialan\n",
      "Loss:1.1691\n",
      "--------\n",
      "Epoch:67\n",
      " Predicted: saaah dlrre\n",
      " Truth: dinah soar\n",
      "Loss:1.1713\n",
      "--------\n",
      "Epoch:68\n",
      " Predicted: mamcionuuu\n",
      " Truth: nunzio\n",
      "Loss:1.1806\n",
      "--------\n",
      "Epoch:69\n",
      " Predicted: mhedrhe    \n",
      " Truth: thais\n",
      "Loss:1.1731\n",
      "--------\n",
      "Epoch:70\n",
      " Predicted: marak u i\n",
      " Truth: xorak\n",
      "Loss:1.1862\n",
      "--------\n",
      "Epoch:71\n",
      " Predicted: seosmaeiu\n",
      " Truth: glimda\n",
      "Loss:1.1754\n",
      "--------\n",
      "Epoch:72\n",
      " Predicted: mlron carmert\n",
      " Truth: aaron verne\n",
      "Loss:1.1740\n",
      "--------\n",
      "Epoch:73\n",
      " Predicted: mnex walonis\n",
      " Truth: alec maloni\n",
      "Loss:1.1675\n",
      "--------\n",
      "Epoch:74\n",
      " Predicted: mhapgra  e \n",
      " Truth: trigona\n",
      "Loss:1.1549\n",
      "--------\n",
      "Epoch:75\n",
      " Predicted: sodecca ragseon\n",
      " Truth: rebecca houston\n",
      "Loss:1.1545\n",
      "--------\n",
      "Epoch:76\n",
      " Predicted: marh c thmotoy burhir\n",
      " Truth: katy <unk> timothy bashir\n",
      "Loss:1.1637\n",
      "--------\n",
      "Epoch:77\n",
      " Predicted: mobyor ,\n",
      " Truth: rok\n",
      "Loss:1.1601\n",
      "--------\n",
      "Epoch:78\n",
      " Predicted: mla bellaaee\n",
      " Truth: eva bell\n",
      "Loss:1.1721\n",
      "--------\n",
      "Epoch:79\n",
      " Predicted: mritn sandolly\n",
      " Truth: orson randall\n",
      "Loss:1.1678\n",
      "--------\n",
      "Epoch:80\n",
      " Predicted: mareme mrather\n",
      " Truth: madame death\n",
      "Loss:1.1539\n",
      "--------\n",
      "Epoch:81\n",
      " Predicted: somes cacoersoi\n",
      " Truth: james jaspers\n",
      "Loss:1.1611\n",
      "--------\n",
      "Epoch:82\n",
      " Predicted: mlichantiner \n",
      " Truth: elephantine\n",
      "Loss:1.1674\n",
      "--------\n",
      "Epoch:83\n",
      " Predicted: mhevnbeck \n",
      " Truth: steinbeck\n",
      "Loss:1.1649\n",
      "--------\n",
      "Epoch:84\n",
      " Predicted: saaan byker,\n",
      " Truth: bryan ryker\n",
      "Loss:1.1603\n",
      "--------\n",
      "Epoch:85\n",
      " Predicted: marcor \n",
      " Truth: mallow\n",
      "Loss:1.1437\n",
      "--------\n",
      "Epoch:86\n",
      " Predicted: mlwmordan\n",
      " Truth: ed jordan\n",
      "Loss:1.2146\n",
      "--------\n",
      "Epoch:87\n",
      " Predicted: mill suntfmanin \n",
      " Truth: wild huntsman i\n",
      "Loss:1.1779\n",
      "--------\n",
      "Epoch:88\n",
      " Predicted: mardtmemplero\n",
      " Truth: zane temple\n",
      "Loss:1.1525\n",
      "--------\n",
      "Epoch:89\n",
      " Predicted: sonoey  \n",
      " Truth: ramsey\n",
      "Loss:1.1520\n",
      "--------\n",
      "Epoch:90\n",
      " Predicted: sardi eximus \n",
      " Truth: magus eximus\n",
      "Loss:1.1362\n",
      "--------\n",
      "Epoch:91\n",
      " Predicted: masd sonastya\n",
      " Truth: ming dynasty\n",
      "Loss:1.1456\n",
      "--------\n",
      "Epoch:92\n",
      " Predicted: mas maerce\n",
      " Truth: mr. meer\n",
      "Loss:1.1465\n",
      "--------\n",
      "Epoch:93\n",
      " Predicted: marcke  i \n",
      " Truth: malice\n",
      "Loss:1.2370\n",
      "--------\n",
      "Epoch:94\n",
      " Predicted: mloer  e\n",
      " Truth: enbe\n",
      "Loss:1.1831\n",
      "--------\n",
      "Epoch:95\n",
      " Predicted: mrrlkn\n",
      " Truth: bulk\n",
      "Loss:1.1468\n",
      "--------\n",
      "Epoch:96\n",
      " Predicted: mamfe  \n",
      " Truth: sayd\n",
      "Loss:1.1456\n",
      "--------\n",
      "Epoch:97\n",
      " Predicted: mroeral whenze\n",
      " Truth: general chen\n",
      "Loss:1.1464\n",
      "--------\n",
      "Epoch:98\n",
      " Predicted: maikos u  \n",
      " Truth: krato\n",
      "Loss:1.2253\n",
      "--------\n",
      "Epoch:99\n",
      " Predicted: alward waltee\n",
      " Truth: edward whit\n",
      "Loss:1.2118\n",
      "CPU times: user 2min 11s, sys: 25.3 s, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx in range((len(dataset)) // batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_in, batch_out = dataset.get_batch(batch_size)\n",
    "        logits, _ = model(batch_in.to(device))\n",
    "        batch_out_flatten = batch_out.view(-1).to(device)\n",
    "        mask = (batch_out_flatten != vocab.pad_idx)\n",
    "        loss = criterion(logits[mask], batch_out_flatten[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    show_predicted_name(epoch, logits, batch_out, vocab)\n",
    "    print(f'Loss:{np.mean(losses[-100:]):.4f}')\n",
    "    if to_print_loss:\n",
    "        plot_loss(epoch, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_superhero_name(model, n_names, vocab):\n",
    "    for _ in range(n_names):\n",
    "        generated_name = model.generate(False, vocab)\n",
    "        print('------------------------------------------------------------------')\n",
    "        print('LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!')\n",
    "        print('CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!')\n",
    "        print('RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!')\n",
    "        print(f'NEW HERO NAMED AS  ----{generated_name.upper()}---!!!!!')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!\n",
      "CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!\n",
      "RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!\n",
      "NEW HERO NAMED AS  ----QUIDER III---!!!!!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!\n",
      "CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!\n",
      "RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!\n",
      "NEW HERO NAMED AS  ----RIGORY EARTERS---!!!!!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!\n",
      "CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!\n",
      "RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!\n",
      "NEW HERO NAMED AS  ----UROYAMA KHANDL---!!!!!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!\n",
      "CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!\n",
      "RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!\n",
      "NEW HERO NAMED AS  ----DWARD LAVENDER---!!!!!\n",
      "\n",
      "------------------------------------------------------------------\n",
      "LADYS AND GENTLEMEN PREPARED TO BW WONDERED BY GROUND NEW SUPERHERO!!!\n",
      "CREATED BY MYSTERIOUS ROBOTIC INTELLIGENT!!!\n",
      "RIGHT FROM LABORATORY OF EVIL GENIUS -- RECCURENT NEURAL NETWORK----!!!\n",
      "NEW HERO NAMED AS  ----HEODORE CHABBO---!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_superhero_name(model, 5, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
